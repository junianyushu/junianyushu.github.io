#Gym
gym 是 OpenAI 开发的一个 强化学习（Reinforcement Learning, RL） 环境库，专门用于创建、训练和测试强化学习算法。它提供了一系列标准化的游戏、机器人控制、物理模拟等环境，方便研究者和开发者快速实验和测试 RL 算法。
##优点
标准化接口，统一的 env.step(action) → (observation, reward, done, info) 交互方式，方便不同算法之间的对比。
丰富的环境：经典控制问题，游戏，，物理模拟，机器人控制，与主流深度学习框架兼容，适用于 TensorFlow、PyTorch，方便集成强化学习算法（DQN、PPO、A3C 等）
以下是一段关于马里奥动作的代码
``` python
# 导入 nes_py 提供的 JoypadSpace 以限制可用按键
from nes_py.wrappers import JoypadSpace

# 导入 gym_super_mario_bros 以创建超级马里奥环境
import gym_super_mario_bros

# 导入 SIMPLE_MOVEMENT，这是一组简化的控制按键
from gym_super_mario_bros.actions import SIMPLE_MOVEMENT

# 导入 time 模块，用于控制渲染速度
import time

# 创建超级马里奥游戏环境
env = gym_super_mario_bros.make('SuperMarioBros-v0')

# 使用 JoypadSpace 限制按键输入为 SIMPLE_MOVEMENT 预定义的动作集合
env = JoypadSpace(env, SIMPLE_MOVEMENT)

# 初始化游戏结束标志
done = True

# 运行 5000 步的游戏循环
for step in range(5000):
    if done:  
        # 如果游戏结束（Mario 死亡或通过关卡），重置环境
        state = env.reset()

    # 让 Mario 随机执行一个动作
    state, reward, done, info = env.step(env.action_space.sample())

    # 让程序稍微暂停，避免画面渲染过快
    time.sleep(0.01)

    # 渲染游戏画面
    env.render()

# 关闭游戏环境
env.close()
```
##使用JoypadSpace
不使用JoypadSpace的话动作空间是离散的，需要使用其来模拟手柄的几个动作，将其固定

![Image](https://github.com/user-attachments/assets/983afab3-9904-424f-9949-7e83c9310ffe)
![Image](https://github.com/user-attachments/assets/d219f8e1-5888-4a35-ba91-3501194156a0)
使用JoypadSpace可令动作固定在7个区间，不适用则动作为离散的
##分析state

![Image](https://github.com/user-attachments/assets/2ff4c118-75f9-48a6-bd3a-df12cda36fe6)
运行后发现像素值为240*256，色彩通道为3，即rgb为彩色
##奖励函数
v：状态之间代理 x 值的差异
在本例中，这是给定步骤的瞬时速度
v = x1 - x0
x0 是步骤之前的 x 位置
x1 是步骤后的 x 位置
向右移动 ⇔ V > 0
左移 ⇔ V < 0
⇔ V = 0 时不移动
c：帧之间的游戏时钟差异
惩罚使代理人无法原地踏步
c = c0 - c1
c0 是 step 之前的 clock 读数
c1 是 step 之后的 clock 读数
没有时钟周期 ⇔ c = 0
时钟刻 ⇔ c < 0
D：对在某个州死亡的代理人进行死刑
这种惩罚会鼓励代理人避免死亡
存活 ⇔ d = 0
死⇔ d = -15
设计奖励函数非常重要，而设计奖励函数往往要通过info来进行参考

coins | int | 收集的硬币数量
flag_get | bool | 如果 Mario 到达了旗帜或斧头，则为 True。
life | int | 剩余的生命数，即 {3， 2， 1}
score | int | 累积游戏内分数
stage | int | 当前阶段，即 {1， ...， 4}
status | str | 马里奥的状态，即 {'small'， 'tall'， 'fireball'}
time | int | 时钟上剩余的时间
world | int | 当前世界，即 {1， ...， 8}
x_pos | int | 马里奥在舞台中的 x 位置（从左到右）
y_pos | int | 马里奥在舞台中的 y 位置（从底部开始）
能否把游戏训练好往往取决于你的奖励函数，当你给予的正反馈足够，模型就会记住这条路径
